{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pretrainedmodels\n",
    "import warnings\n",
    "import gc\n",
    "import pandas as pd\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils.utils_data_load import *\n",
    "from train.train_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "model_path = '../results/'\n",
    "experiment = 'resnet34_1'\n",
    "description = 'center crop resnet 34'\n",
    "model_path = os.path.join(model_path, experiment)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    \n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, 'description.txt'), 'w') as f:\n",
    "    f.write(\"%s\\n\" % description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensor\n",
    "from albumentations import (Compose, CenterCrop, VerticalFlip,\n",
    "                            HorizontalFlip, HueSaturationValue, Resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensor\n",
    "from albumentations import (Compose, CenterCrop, VerticalFlip,\n",
    "                            HorizontalFlip, HueSaturationValue, Resize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_loader import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': Compose([\n",
    "    CenterCrop(224, 224), \n",
    "    VerticalFlip(),\n",
    "    HorizontalFlip(),\n",
    "    HueSaturationValue(),\n",
    "    ToTensor()\n",
    "]),\n",
    "    'val': Compose([\n",
    "    CenterCrop(224, 224), \n",
    "    ToTensor()\n",
    "]),\n",
    "    'test': Compose([\n",
    "    CenterCrop(224, 224), \n",
    "    ToTensor()\n",
    "]),\n",
    "}\n",
    "def change_classes(x):\n",
    "    return 1 - x\n",
    "\n",
    "target_transform = change_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "VAL data fold_0\n",
      "==========\n",
      "Epoch 0/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 8/141 [00:03<01:05,  2.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-87a92fac7c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                num_epochs=3, fold_name=folds[vl][0])\n\u001b[0m\u001b[1;32m     39\u001b[0m     torch.save(model_ft.state_dict(),\n\u001b[1;32m     40\u001b[0m                os.path.join(model_path, 'val_' + folds[vl][0] + '_f1_05_' + str(best_score).replace('.', '')))\n",
      "\u001b[0;32m~/cell_project/cell_project/train/train_functions.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, model_path, device, fold_name, use_gpu, num_epochs, plot_res, predict_test, save_val)\u001b[0m\n\u001b[1;32m     80\u001b[0m             loss = criterion(outputs.type(torch.cuda.FloatTensor)[:, 1],\n\u001b[1;32m     81\u001b[0m                              labels.type(torch.cuda.FloatTensor))\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-1*x))\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "folds = np.array(['fold_0','fold_1','fold_2', 'fold_3'])\n",
    "#models = []\n",
    "results = pd.DataFrame()\n",
    "device  = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for tr, vl in loo.split(folds):\n",
    "    model_ft = pretrainedmodels.__dict__['se_resnext50_32x4d'](num_classes=1000, pretrained='imagenet')\n",
    "\n",
    "    model_ft.last_linear = nn.Linear(2048, 20)\n",
    "\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "    params_to_train = model_ft.parameters()\n",
    "    optimizer_ft = torch.optim.Adam(params_to_train)\n",
    "    plat_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft,\n",
    "                                                           'min', patience=3,\n",
    "                                                           factor=0.999, verbose=True)\n",
    "\n",
    "    train_folds = folds[tr]\n",
    "    val_folds = folds[vl]\n",
    "    test_data = ['test']\n",
    "\n",
    "    dataloaders, dataset_sizes, class_names = loader(data_transforms, train_folds, val_folds,\n",
    "                                                         test_data, data_dir, bs=64, target_transform=target_transform)\n",
    "    \n",
    "    model_ft, best_score = train_model(model_ft, criterion, optimizer_ft,\n",
    "                               plat_lr_scheduler,\n",
    "                               dataset_sizes=dataset_sizes,\n",
    "                               model_path=model_path,\n",
    "                               dataloaders=dataloaders,\n",
    "                               device=device, \n",
    "                               num_epochs=3, fold_name=folds[vl][0])\n",
    "    torch.save(model_ft.state_dict(),\n",
    "               os.path.join(model_path, 'val_' + folds[vl][0] + '_f1_05_' + str(best_score).replace('.', '')))\n",
    "    del criterion, optimizer_ft, plat_lr_scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
